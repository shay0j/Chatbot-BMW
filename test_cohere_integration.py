"""
Test integracji RAG z Cohere - ZAKTUALIZOWANA WERSJA
UÅ¼ywa modelu command-r7b-12-2024 zamiast command
"""
import asyncio
import sys
import os
from pathlib import Path

# Dodaj Å›cieÅ¼kÄ™ do projektu
sys.path.append(str(Path(__file__).parent))

import cohere
from app.services.rag_service import get_rag_service
from app.core.config import settings

class BMWChatbotV2:
    def __init__(self):
        self.rag_service = None
        self.cohere_client = None
        self.model_name = "command-r7b-12-2024"  # UÅ¼yj modelu z configu
        
    async def initialize(self):
        """Inicjalizuje RAG i Cohere"""
        print("ğŸš€ Inicjalizacja BMW Chatbot v2...")
        
        # 1. Inicjalizuj RAG service
        self.rag_service = await get_rag_service()
        print("âœ… RAG Service zainicjalizowany")
        
        # 2. Inicjalizuj Cohere client
        try:
            self.cohere_client = cohere.Client(api_key=settings.COHERE_API_KEY)
            print("âœ… Cohere Client zainicjalizowany")
            
            # SprawdÅº dostÄ™pne modele
            print(f"ğŸ”„ UÅ¼ywam modelu: {self.model_name}")
            
        except Exception as e:
            print(f"âŒ BÅ‚Ä…d Cohere: {e}")
            return False
        
        return True
    
    async def get_rag_context(self, query: str) -> dict:
        """Pobiera kontekst z RAG"""
        return await self.rag_service.retrieve_with_intent_check(query)
    
    def build_prompt(self, query: str, rag_result: dict) -> str:
        """Buduje prompt dla Cohere"""
        
        if not rag_result["has_data"]:
            return f'''JesteÅ› asystentem BMW. Klient zadaÅ‚ pytanie, ale nie masz informacji w bazie.

Pytanie: {query}

Odpowiedz: "Przepraszam, nie znalazÅ‚em informacji na ten temat w bazie danych BMW. Czy mogÄ™ pomÃ³c w czymÅ› innym?"'''
        
        # Przygotuj kontekst
        context_parts = ["INFORMACJE Z BMW.PL:"]
        for i, doc in enumerate(rag_result["documents"][:3]):
            content = ' '.join(doc["content"].split()[:80])  # Pierwsze 80 sÅ‚Ã³w
            context_parts.append(f"{i+1}. {content}")
        
        context = "\n\n".join(context_parts)
        
        # Detekcja intencji dla lepszej odpowiedzi
        intent = rag_result["intent"]
        intent_hint = ""
        
        if intent == "price":
            intent_hint = "JeÅ›li pytasz o cenÄ™, podaj zakres cenowy jeÅ›li jest w informacjach."
        elif intent == "technical":
            intent_hint = "JeÅ›li pytasz o specyfikacjÄ™, podaj konkretne liczby jeÅ›li sÄ… w informacjach."
        
        prompt = f'''JesteÅ› asystentem BMW w Polsce. Twoim zadaniem jest odpowiadanie na pytania klientÃ³w uÅ¼ywajÄ…c TYLKO poniÅ¼szych informacji z oficjalnej strony bmw.pl.

{context}

WAÅ»NE ZASADY:
1. Odpowiadaj WYÅÄ„CZNIE po POLSKU
2. UÅ¼ywaj TYLKO informacji z powyÅ¼szego kontekstu
3. JeÅ›li odpowiedzi nie ma w kontekÅ›cie, powiedz "Nie mam tej informacji w bazie danych"
4. BÄ…dÅº konkretny i pomocny
5. {intent_hint}

PYTANIE KLIENTA: {query}

ODPOWIEDÅ¹ ASYSTENTA BMW (krÃ³tko i na temat):'''
        
        return prompt
    
    async def generate_response(self, query: str) -> str:
        """Generuje odpowiedÅº uÅ¼ywajÄ…c RAG + Cohere"""
        
        # 1. Pobierz kontekst z RAG
        rag_result = await self.get_rag_context(query)
        
        # Loguj info
        print(f"\nğŸ” RAG dla '{query[:30]}...':")
        print(f"   - Has data: {rag_result['has_data']}")
        print(f"   - Intent: {rag_result['intent']}")
        print(f"   - Confidence: {rag_result['confidence']:.3f}")
        
        # 2. Zbuduj prompt
        prompt = self.build_prompt(query, rag_result)
        
        # 3. WywoÅ‚aj Cohere API
        try:
            # SPRAWDÅ¹ CZY TO DZIAÅA - rÃ³Å¼ne podejÅ›cia
            
            # Metoda 1: generate() - moÅ¼e jeszcze dziaÅ‚aÄ‡
            try:
                response = self.cohere_client.generate(
                    model=self.model_name,
                    prompt=prompt,
                    max_tokens=250,
                    temperature=0.3,
                    truncate='END'
                )
                return response.generations[0].text.strip()
            except Exception as e1:
                print(f"âš ï¸  Generate nie dziaÅ‚a: {e1}")
                
                # Metoda 2: chat() bez chat_history
                try:
                    response = self.cohere_client.chat(
                        model=self.model_name,
                        message=prompt,
                        temperature=0.3,
                        max_tokens=250
                    )
                    return response.text.strip()
                except Exception as e2:
                    print(f"âš ï¸  Chat nie dziaÅ‚a: {e2}")
                    
                    # Metoda 3: chat() z message tylko jako query
                    try:
                        system_msg = prompt.split("PYTANIE KLIENTA:")[0]
                        user_query = query
                        
                        response = self.cohere_client.chat(
                            model=self.model_name,
                            message=user_query,
                            preamble=system_msg,
                            temperature=0.3,
                            max_tokens=250
                        )
                        return response.text.strip()
                    except Exception as e3:
                        print(f"âš ï¸  Chat z preamble nie dziaÅ‚a: {e3}")
                        
                        # Fallback
                        return await self.fallback_response(rag_result)
                        
        except Exception as e:
            print(f"âŒ Wszystkie metody Cohere zawiodÅ‚y: {e}")
            return await self.fallback_response(rag_result)
    
    async def fallback_response(self, rag_result: dict) -> str:
        """Fallback gdy Cohere nie dziaÅ‚a"""
        if not rag_result["has_data"]:
            return "Przepraszam, nie znalazÅ‚em informacji na ten temat."
        
        first_doc = rag_result["documents"][0]["content"]
        words = first_doc.split()[:40]
        preview = " ".join(words) + ("..." if len(words) == 40 else "")
        
        intent = rag_result["intent"]
        
        if intent == "price":
            return f"Z informacji dostÄ™pnych: {preview} Aby poznaÄ‡ dokÅ‚adnÄ… cenÄ™, skontaktuj siÄ™ z dealerem BMW."
        elif intent == "technical":
            return f"Specyfikacja: {preview}"
        else:
            return f"Informacje: {preview}"
    
    async def chat_loop(self):
        """Interaktywna pÄ™tla chat"""
        print("\n" + "="*60)
        print("ğŸ¤– BMW CHATBOT v2 - command-r7b-12-2024")
        print("="*60)
        print("Zadawaj pytania o BMW!")
        print("'stats' - statystyki RAG")
        print("'exit' - zakoÅ„cz")
        print("="*60)
        
        while True:
            try:
                user_input = input("\nğŸ‘¤ Ty: ").strip()
                
                if user_input.lower() == 'exit':
                    print("\nğŸš— Do widzenia!")
                    break
                
                elif user_input.lower() == 'stats':
                    stats = await self.rag_service.get_stats()
                    print(f"\nğŸ“Š Statystyki: {stats['queries_processed']} zapytaÅ„, {stats['documents_in_store']} dokumentÃ³w")
                    continue
                
                print("â³ MyÅ›lÄ™...")
                response = await self.generate_response(user_input)
                print(f"\nğŸ¤– BMW Assistant: {response}")
                
            except KeyboardInterrupt:
                print("\n\nDo widzenia!")
                break
            except Exception as e:
                print(f"\nâŒ BÅ‚Ä…d: {e}")

async def main():
    """GÅ‚Ã³wna funkcja"""
    chatbot = BMWChatbotV2()
    
    # Inicjalizacja
    if not await chatbot.initialize():
        print("\nâŒ Nie udaÅ‚o siÄ™ zainicjalizowaÄ‡.")
        print("SprawdÅº:")
        print("1. Klucz API Cohere w .env lub config.py")
        print("2. Czy model 'command-r7b-12-2024' jest dostÄ™pny")
        print("3. Czy masz aktualnÄ… wersjÄ™ biblioteki cohere")
        return
    
    # Szybkie testy
    print("\nğŸ§ª TestujÄ™ podstawowe zapytania...")
    
    test_queries = [
        "BMW X3",
        "Ile kosztuje BMW X5?",
        "Moc silnika Seria 3",
    ]
    
    for query in test_queries:
        print(f"\n{'='*40}")
        print(f"ğŸ“ Zapytanie: {query}")
        
        response = await chatbot.generate_response(query)
        print(f"ğŸ¤– OdpowiedÅº: {response}")
        
        await asyncio.sleep(1)
    
    print("\nâœ… Testy zakoÅ„czone! Rozpoczynam interaktywny chat...")
    await chatbot.chat_loop()

if __name__ == "__main__":
    asyncio.run(main())